{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, I want to continue working with the model form the experiment 1. The model was able to learn the steering angles for the three hand-picked images but the question is can it learn to actually steer the car in the simulator's autonomous mode. Given the discussion about recovery in the project material, it is unlikely that the provided sample training data is enough to teach the model to drive, but doing a test with that data would give at least a baseline to work from.\n",
    "\n",
    "Here is the overall plan\n",
    "1. Recreate the model from experiment 1\n",
    "1. Create training data using the provided sample data\n",
    "1. Train the model using the whole training data and see if it any learning takes place\n",
    "1. If needed, tweak the model to get better training performance\n",
    "1. Test the model with the simulator to see how it performs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def get_record_and_image(index):\n",
    "    record = df.iloc[index]\n",
    "    path = os.path.join('data', record.center)\n",
    "    return record, Image.open(path)\n",
    "\n",
    "def layer_info(model):\n",
    "    for n, layer in enumerate(model.layers, 1):\n",
    "        print('Layer {:2} {:16} input shape {} output shape {}'.format(n, layer.name, layer.input_shape, layer.output_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Recreate the model from experiment 1\n",
    "\n",
    "This is an exact copy of the model from experiment 1 with one difference: the input image size is halved, because the images will be downscaled this time. The reason for the downscaling is explained in Step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer  1 convolution2d_1  input shape (None, 80, 160, 3) output shape (None, 16, 32, 6)\n",
      "Layer  2 activation_1     input shape (None, 16, 32, 6) output shape (None, 16, 32, 6)\n",
      "Layer  3 maxpooling2d_1   input shape (None, 16, 32, 6) output shape (None, 8, 16, 6)\n",
      "Layer  4 convolution2d_2  input shape (None, 8, 16, 6) output shape (None, 2, 6, 16)\n",
      "Layer  5 activation_2     input shape (None, 2, 6, 16) output shape (None, 2, 6, 16)\n",
      "Layer  6 maxpooling2d_2   input shape (None, 2, 6, 16) output shape (None, 1, 3, 16)\n",
      "Layer  7 flatten_1        input shape (None, 1, 3, 16) output shape (None, 48)\n",
      "Layer  8 dense_1          input shape (None, 48) output shape (None, 120)\n",
      "Layer  9 activation_3     input shape (None, 120) output shape (None, 120)\n",
      "Layer 10 dense_2          input shape (None, 120) output shape (None, 84)\n",
      "Layer 11 activation_4     input shape (None, 84) output shape (None, 84)\n",
      "Layer 12 dense_3          input shape (None, 84) output shape (None, 1)\n",
      "Layer 13 activation_5     input shape (None, 1) output shape (None, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(6, 5, 5, border_mode='valid', subsample=(5, 5), input_shape=(80, 160, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(16, 5, 5, border_mode='valid', subsample=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(84))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('tanh'))\n",
    "\n",
    "layer_info(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/driving_log.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to create the actual training data, X_train and y_train. I will just read all the images and store them as NumPy arrays to X_train. Similary, I read the corresponding steering angles and store them to y_train.\n",
    "\n",
    "Note: I ended up scaling the images down to half size to conserve memory and speed up training. This was also mentioned in the project cheat sheet (https://carnd-forums.udacity.com/questions/26214464/behavioral-cloning-cheatsheet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8036/8036 [00:12<00:00, 638.86it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    record, image = get_record_and_image(i)\n",
    "    image = image.resize((image.width // 2, image.height // 2))\n",
    "    X_train.append(np.array(image))\n",
    "    image.close()\n",
    "    y_train.append(record['steering'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some preprocessing: normalize the images and convert the y_train to a NumPy array because that is what the Keras fit() seems to want. This step takes some time and consumes also a lot of memory; downscaling the images above helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_min = np.min(X_train)\n",
    "X_max = np.max(X_train)\n",
    "X_normalized = (X_train - X_min) / (X_max - X_min) - 0.5\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train the model\n",
    "\n",
    "Here I use all the data from the sample training data, 8036 images and their steering angles. Instead of using the training data generator as in the experiment 1, I just give the whole training set to model.fit and let it split it to training and validation sets. After training, I save the model so it can be loaded to the simulator for testing if the training seems to proceed well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras.optimizers\n",
    "\n",
    "def train(model, nb_epoch=10, learning_rate=0.001):\n",
    "    adam = keras.optimizers.Adam(lr=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=adam)\n",
    "    model.fit(X_normalized, y_train, validation_split=0.2, nb_epoch=nb_epoch, verbose=2)\n",
    "    model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6428 samples, validate on 1608 samples\n",
      "Epoch 1/10\n",
      "6s - loss: 0.0124 - val_loss: 0.0114\n",
      "Epoch 2/10\n",
      "2s - loss: 0.0099 - val_loss: 0.0113\n",
      "Epoch 3/10\n",
      "2s - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 4/10\n",
      "2s - loss: 0.0086 - val_loss: 0.0116\n",
      "Epoch 5/10\n",
      "2s - loss: 0.0082 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "2s - loss: 0.0078 - val_loss: 0.0107\n",
      "Epoch 7/10\n",
      "2s - loss: 0.0075 - val_loss: 0.0109\n",
      "Epoch 8/10\n",
      "2s - loss: 0.0070 - val_loss: 0.0111\n",
      "Epoch 9/10\n",
      "2s - loss: 0.0066 - val_loss: 0.0112\n",
      "Epoch 10/10\n",
      "2s - loss: 0.0063 - val_loss: 0.0117\n"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation error does not get much lower after epoch 4 or so, whereas the training error keeps falling. This indicates overtraining and poor generalization ability. \n",
    "\n",
    "Lets do a bit of random sampling of the predicted steering angles to get a feeling how they match with the actual angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual steering angle 0.0 model prediction 0.04371071606874466\n",
      "Actual steering angle -0.22116129999999998 model prediction -0.26435205340385437\n",
      "Actual steering angle 0.09046549999999999 model prediction 0.051914017647504807\n",
      "Actual steering angle 0.1287396 model prediction 0.008762470446527004\n",
      "Actual steering angle 0.03305431 model prediction 0.05218489095568657\n",
      "Actual steering angle 0.1670138 model prediction 0.024041639640927315\n",
      "Actual steering angle 0.3488158 model prediction 0.30565115809440613\n",
      "Actual steering angle 0.0 model prediction 0.015904072672128677\n",
      "Actual steering angle 0.0 model prediction 0.020633550360798836\n",
      "Actual steering angle 0.0 model prediction -0.005549779627472162\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "\n",
    "def sample_predictions(model):\n",
    "    for i in range(10):\n",
    "        index = randrange(len(df))\n",
    "        X = np.expand_dims(X_normalized[index], axis=0)\n",
    "        y = y_train[index]\n",
    "        print('Actual steering angle {} model prediction {}'.format(y, model.predict(X)[0][0]))\n",
    "        \n",
    "sample_predictions(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The sample predictions do not look very good. Some tweaks to the model are in place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Tweaking the model\n",
    "\n",
    "So what could be done to the model to improve it? Basically there are three different approaches for changing the model:\n",
    "\n",
    "1. Keep the model as it is, but try to improve its generalization ability\n",
    "2. Keep the current architecture, but increase the amount of weights\n",
    "3. Do some changes to the model's architecture\n",
    "\n",
    "Before going for options 2 or 3, let's consider option 1 as it is more conservative than the other. A simple way to try to increase the generalization ability is add dropout layers, which force the model to learn redundant connections. Let's try that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer  1 convolution2d_4  input shape (None, 80, 160, 3) output shape (None, 16, 32, 6)\n",
      "Layer  2 dropout_1        input shape (None, 16, 32, 6) output shape (None, 16, 32, 6)\n",
      "Layer  3 activation_6     input shape (None, 16, 32, 6) output shape (None, 16, 32, 6)\n",
      "Layer  4 maxpooling2d_3   input shape (None, 16, 32, 6) output shape (None, 8, 16, 6)\n",
      "Layer  5 convolution2d_5  input shape (None, 8, 16, 6) output shape (None, 2, 6, 16)\n",
      "Layer  6 dropout_2        input shape (None, 2, 6, 16) output shape (None, 2, 6, 16)\n",
      "Layer  7 activation_7     input shape (None, 2, 6, 16) output shape (None, 2, 6, 16)\n",
      "Layer  8 maxpooling2d_4   input shape (None, 2, 6, 16) output shape (None, 1, 3, 16)\n",
      "Layer  9 flatten_2        input shape (None, 1, 3, 16) output shape (None, 48)\n",
      "Layer 10 dense_4          input shape (None, 48) output shape (None, 120)\n",
      "Layer 11 activation_8     input shape (None, 120) output shape (None, 120)\n",
      "Layer 12 dense_5          input shape (None, 120) output shape (None, 84)\n",
      "Layer 13 activation_9     input shape (None, 84) output shape (None, 84)\n",
      "Layer 14 dense_6          input shape (None, 84) output shape (None, 1)\n",
      "Layer 15 activation_10    input shape (None, 1) output shape (None, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "model_2 = Sequential()\n",
    "model_2.add(Convolution2D(6, 5, 5, border_mode='valid', subsample=(5, 5), input_shape=(80, 160, 3)))\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_2.add(Convolution2D(16, 5, 5, border_mode='valid', subsample=(2, 2)))\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(120))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Dense(84))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Dense(1))\n",
    "model_2.add(Activation('tanh'))\n",
    "\n",
    "layer_info(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6428 samples, validate on 1608 samples\n",
      "Epoch 1/10\n",
      "3s - loss: 0.0163 - val_loss: 0.0164\n",
      "Epoch 2/10\n",
      "2s - loss: 0.0144 - val_loss: 0.0159\n",
      "Epoch 3/10\n",
      "2s - loss: 0.0131 - val_loss: 0.0151\n",
      "Epoch 4/10\n",
      "2s - loss: 0.0128 - val_loss: 0.0144\n",
      "Epoch 5/10\n",
      "2s - loss: 0.0123 - val_loss: 0.0133\n",
      "Epoch 6/10\n",
      "2s - loss: 0.0119 - val_loss: 0.0142\n",
      "Epoch 7/10\n",
      "2s - loss: 0.0115 - val_loss: 0.0130\n",
      "Epoch 8/10\n",
      "2s - loss: 0.0113 - val_loss: 0.0131\n",
      "Epoch 9/10\n",
      "2s - loss: 0.0112 - val_loss: 0.0131\n",
      "Epoch 10/10\n",
      "2s - loss: 0.0111 - val_loss: 0.0131\n",
      "Actual steering angle 0.0 model prediction 0.03387485072016716\n",
      "Actual steering angle 0.0 model prediction 0.01597663387656212\n",
      "Actual steering angle 0.0 model prediction 0.02428283914923668\n",
      "Actual steering angle 0.0 model prediction 0.0340711735188961\n",
      "Actual steering angle -0.14520639999999999 model prediction -0.0008674438577145338\n",
      "Actual steering angle 0.05219137 model prediction 0.04443788528442383\n",
      "Actual steering angle 0.0 model prediction -0.008976426906883717\n",
      "Actual steering angle 0.0 model prediction -0.01802789978682995\n",
      "Actual steering angle 0.04262284 model prediction 0.06426456570625305\n",
      "Actual steering angle -0.32559920000000003 model prediction -0.04883846640586853\n"
     ]
    }
   ],
   "source": [
    "train(model_2)\n",
    "sample_predictions(model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performace is even poorer now so the model is probably not complex enough to learn the given data set. I could increase the layer dimensions directly, but there is another way: remove the pooling layers. Pooling is analogous to downsampling and it reduces the amount of weights in the model. Let's strip the pooling layers and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer  1 convolution2d_6  input shape (None, 80, 160, 3) output shape (None, 16, 32, 6)\n",
      "Layer  2 dropout_3        input shape (None, 16, 32, 6) output shape (None, 16, 32, 6)\n",
      "Layer  3 activation_11    input shape (None, 16, 32, 6) output shape (None, 16, 32, 6)\n",
      "Layer  4 convolution2d_7  input shape (None, 16, 32, 6) output shape (None, 12, 28, 16)\n",
      "Layer  5 dropout_4        input shape (None, 12, 28, 16) output shape (None, 12, 28, 16)\n",
      "Layer  6 activation_12    input shape (None, 12, 28, 16) output shape (None, 12, 28, 16)\n",
      "Layer  7 flatten_3        input shape (None, 12, 28, 16) output shape (None, 5376)\n",
      "Layer  8 dense_7          input shape (None, 5376) output shape (None, 120)\n",
      "Layer  9 activation_13    input shape (None, 120) output shape (None, 120)\n",
      "Layer 10 dense_8          input shape (None, 120) output shape (None, 84)\n",
      "Layer 11 activation_14    input shape (None, 84) output shape (None, 84)\n",
      "Layer 12 dense_9          input shape (None, 84) output shape (None, 1)\n",
      "Layer 13 activation_15    input shape (None, 1) output shape (None, 1)\n"
     ]
    }
   ],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(Convolution2D(6, 5, 5, border_mode='valid', subsample=(5, 5), input_shape=(80, 160, 3)))\n",
    "model_3.add(Dropout(0.5))\n",
    "model_3.add(Activation('relu'))\n",
    "#model_3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_3.add(Convolution2D(16, 5, 5, border_mode='valid'))\n",
    "model_3.add(Dropout(0.5))\n",
    "model_3.add(Activation('relu'))\n",
    "#model_3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_3.add(Flatten())\n",
    "model_3.add(Dense(120))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(Dense(84))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(Dense(1))\n",
    "model_3.add(Activation('tanh'))\n",
    "\n",
    "layer_info(model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6428 samples, validate on 1608 samples\n",
      "Epoch 1/20\n",
      "4s - loss: 0.0135 - val_loss: 0.0112\n",
      "Epoch 2/20\n",
      "3s - loss: 0.0107 - val_loss: 0.0124\n",
      "Epoch 3/20\n",
      "3s - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 4/20\n",
      "3s - loss: 0.0095 - val_loss: 0.0116\n",
      "Epoch 5/20\n",
      "3s - loss: 0.0091 - val_loss: 0.0103\n",
      "Epoch 6/20\n",
      "3s - loss: 0.0089 - val_loss: 0.0103\n",
      "Epoch 7/20\n",
      "3s - loss: 0.0087 - val_loss: 0.0100\n",
      "Epoch 8/20\n",
      "3s - loss: 0.0085 - val_loss: 0.0112\n",
      "Epoch 9/20\n",
      "3s - loss: 0.0083 - val_loss: 0.0114\n",
      "Epoch 10/20\n",
      "3s - loss: 0.0082 - val_loss: 0.0104\n",
      "Epoch 11/20\n",
      "3s - loss: 0.0082 - val_loss: 0.0107\n",
      "Epoch 12/20\n",
      "3s - loss: 0.0077 - val_loss: 0.0108\n",
      "Epoch 13/20\n",
      "3s - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 14/20\n",
      "3s - loss: 0.0076 - val_loss: 0.0100\n",
      "Epoch 15/20\n",
      "3s - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 16/20\n",
      "3s - loss: 0.0072 - val_loss: 0.0107\n",
      "Epoch 17/20\n",
      "3s - loss: 0.0072 - val_loss: 0.0104\n",
      "Epoch 18/20\n",
      "3s - loss: 0.0071 - val_loss: 0.0118\n",
      "Epoch 19/20\n",
      "3s - loss: 0.0068 - val_loss: 0.0102\n",
      "Epoch 20/20\n",
      "3s - loss: 0.0066 - val_loss: 0.0114\n",
      "Actual steering angle 0.0 model prediction 0.007433527614921331\n",
      "Actual steering angle 0.3583844 model prediction 0.2920953631401062\n",
      "Actual steering angle 0.10960260000000001 model prediction 0.14672048389911652\n",
      "Actual steering angle 0.0 model prediction 0.003169712610542774\n",
      "Actual steering angle 0.08089697 model prediction 0.04634883627295494\n",
      "Actual steering angle -0.35408229999999996 model prediction -0.3030298948287964\n",
      "Actual steering angle 0.0 model prediction 0.06416530162096024\n",
      "Actual steering angle 0.0 model prediction -0.0014916735235601664\n",
      "Actual steering angle 0.0 model prediction 0.017649848014116287\n",
      "Actual steering angle -0.1736895 model prediction -0.03422090411186218\n"
     ]
    }
   ],
   "source": [
    "train(model_3, 20)\n",
    "sample_predictions(model_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit better but even after 20 epochs not that much of an improvement. I begin to suspect that I need to increase the model's complexity quite a bit. At this point I will try to replicate the architecture from the NVidia paper (http://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf) and see what kind of difference it makes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer  1 convolution2d_8  input shape (None, 80, 160, 3) output shape (None, 38, 78, 24)\n",
      "Layer  2 activation_16    input shape (None, 38, 78, 24) output shape (None, 38, 78, 24)\n",
      "Layer  3 convolution2d_9  input shape (None, 38, 78, 24) output shape (None, 17, 37, 36)\n",
      "Layer  4 activation_17    input shape (None, 17, 37, 36) output shape (None, 17, 37, 36)\n",
      "Layer  5 convolution2d_10 input shape (None, 17, 37, 36) output shape (None, 7, 17, 48)\n",
      "Layer  6 activation_18    input shape (None, 7, 17, 48) output shape (None, 7, 17, 48)\n",
      "Layer  7 convolution2d_11 input shape (None, 7, 17, 48) output shape (None, 5, 15, 64)\n",
      "Layer  8 activation_19    input shape (None, 5, 15, 64) output shape (None, 5, 15, 64)\n",
      "Layer  9 convolution2d_12 input shape (None, 5, 15, 64) output shape (None, 3, 13, 64)\n",
      "Layer 10 activation_20    input shape (None, 3, 13, 64) output shape (None, 3, 13, 64)\n",
      "Layer 11 flatten_4        input shape (None, 3, 13, 64) output shape (None, 2496)\n",
      "Layer 12 dense_10         input shape (None, 2496) output shape (None, 100)\n",
      "Layer 13 activation_21    input shape (None, 100) output shape (None, 100)\n",
      "Layer 14 dense_11         input shape (None, 100) output shape (None, 50)\n",
      "Layer 15 activation_22    input shape (None, 50) output shape (None, 50)\n",
      "Layer 16 dense_12         input shape (None, 50) output shape (None, 10)\n",
      "Layer 17 activation_23    input shape (None, 10) output shape (None, 10)\n",
      "Layer 18 dense_13         input shape (None, 10) output shape (None, 1)\n",
      "Layer 19 activation_24    input shape (None, 1) output shape (None, 1)\n"
     ]
    }
   ],
   "source": [
    "model_4 = Sequential()\n",
    "model_4.add(Convolution2D(24, 5, 5, border_mode='valid', subsample=(2, 2), input_shape=(80, 160, 3)))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Convolution2D(36, 5, 5, border_mode='valid', subsample=(2, 2)))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Convolution2D(48, 5, 5, border_mode='valid', subsample=(2, 2)))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Convolution2D(64, 3, 3, border_mode='valid'))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Convolution2D(64, 3, 3, border_mode='valid'))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Flatten())\n",
    "model_4.add(Dense(100))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dense(50))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dense(10))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dense(1))\n",
    "model_4.add(Activation('tanh'))\n",
    "\n",
    "layer_info(model_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6428 samples, validate on 1608 samples\n",
      "Epoch 1/10\n",
      "8s - loss: 0.0131 - val_loss: 0.0123\n",
      "Epoch 2/10\n",
      "7s - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 3/10\n",
      "7s - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 4/10\n",
      "7s - loss: 0.0092 - val_loss: 0.0102\n",
      "Epoch 5/10\n",
      "7s - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 6/10\n",
      "7s - loss: 0.0081 - val_loss: 0.0105\n",
      "Epoch 7/10\n",
      "7s - loss: 0.0075 - val_loss: 0.0107\n",
      "Epoch 8/10\n",
      "7s - loss: 0.0069 - val_loss: 0.0102\n",
      "Epoch 9/10\n",
      "7s - loss: 0.0063 - val_loss: 0.0110\n",
      "Epoch 10/10\n",
      "7s - loss: 0.0055 - val_loss: 0.0114\n",
      "Actual steering angle 0.0 model prediction 0.05460153520107269\n",
      "Actual steering angle 0.04262284 model prediction 0.019047563895583153\n",
      "Actual steering angle 0.0 model prediction -0.00044491884182207286\n",
      "Actual steering angle -0.3066105 model prediction -0.012816531583666801\n",
      "Actual steering angle 0.0 model prediction -0.011746209114789963\n",
      "Actual steering angle 0.1765823 model prediction 0.1348859667778015\n",
      "Actual steering angle 0.01391724 model prediction 0.14430499076843262\n",
      "Actual steering angle 0.21485639999999998 model prediction 0.22075293958187103\n",
      "Actual steering angle -0.08824026 model prediction -0.11307830363512039\n",
      "Actual steering angle 0.1765823 model prediction 0.2046814262866974\n"
     ]
    }
   ],
   "source": [
    "train(model_4)\n",
    "sample_predictions(model_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer  1 convolution2d_13 input shape (None, 80, 160, 3) output shape (None, 38, 78, 24)\n",
      "Layer  2 activation_25    input shape (None, 38, 78, 24) output shape (None, 38, 78, 24)\n",
      "Layer  3 dropout_5        input shape (None, 38, 78, 24) output shape (None, 38, 78, 24)\n",
      "Layer  4 convolution2d_14 input shape (None, 38, 78, 24) output shape (None, 17, 37, 36)\n",
      "Layer  5 activation_26    input shape (None, 17, 37, 36) output shape (None, 17, 37, 36)\n",
      "Layer  6 dropout_6        input shape (None, 17, 37, 36) output shape (None, 17, 37, 36)\n",
      "Layer  7 convolution2d_15 input shape (None, 17, 37, 36) output shape (None, 7, 17, 48)\n",
      "Layer  8 activation_27    input shape (None, 7, 17, 48) output shape (None, 7, 17, 48)\n",
      "Layer  9 dropout_7        input shape (None, 7, 17, 48) output shape (None, 7, 17, 48)\n",
      "Layer 10 convolution2d_16 input shape (None, 7, 17, 48) output shape (None, 5, 15, 64)\n",
      "Layer 11 activation_28    input shape (None, 5, 15, 64) output shape (None, 5, 15, 64)\n",
      "Layer 12 dropout_8        input shape (None, 5, 15, 64) output shape (None, 5, 15, 64)\n",
      "Layer 13 convolution2d_17 input shape (None, 5, 15, 64) output shape (None, 3, 13, 64)\n",
      "Layer 14 activation_29    input shape (None, 3, 13, 64) output shape (None, 3, 13, 64)\n",
      "Layer 15 dropout_9        input shape (None, 3, 13, 64) output shape (None, 3, 13, 64)\n",
      "Layer 16 flatten_5        input shape (None, 3, 13, 64) output shape (None, 2496)\n",
      "Layer 17 dense_14         input shape (None, 2496) output shape (None, 100)\n",
      "Layer 18 activation_30    input shape (None, 100) output shape (None, 100)\n",
      "Layer 19 dense_15         input shape (None, 100) output shape (None, 50)\n",
      "Layer 20 activation_31    input shape (None, 50) output shape (None, 50)\n",
      "Layer 21 dense_16         input shape (None, 50) output shape (None, 10)\n",
      "Layer 22 activation_32    input shape (None, 10) output shape (None, 10)\n",
      "Layer 23 dense_17         input shape (None, 10) output shape (None, 1)\n",
      "Layer 24 activation_33    input shape (None, 1) output shape (None, 1)\n"
     ]
    }
   ],
   "source": [
    "model_4 = Sequential()\n",
    "model_4.add(Convolution2D(24, 5, 5, border_mode='valid', subsample=(2, 2), input_shape=(80, 160, 3)))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dropout(0.5))\n",
    "model_4.add(Convolution2D(36, 5, 5, border_mode='valid', subsample=(2, 2)))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dropout(0.5))\n",
    "model_4.add(Convolution2D(48, 5, 5, border_mode='valid', subsample=(2, 2)))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dropout(0.5))\n",
    "model_4.add(Convolution2D(64, 3, 3, border_mode='valid'))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dropout(0.5))\n",
    "model_4.add(Convolution2D(64, 3, 3, border_mode='valid'))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dropout(0.5))\n",
    "model_4.add(Flatten())\n",
    "model_4.add(Dense(100))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dense(50))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dense(10))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dense(1))\n",
    "model_4.add(Activation('tanh'))\n",
    "\n",
    "layer_info(model_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6428 samples, validate on 1608 samples\n",
      "Epoch 1/10\n",
      "9s - loss: 0.0141 - val_loss: 0.0134\n",
      "Epoch 2/10\n",
      "8s - loss: 0.0116 - val_loss: 0.0131\n",
      "Epoch 3/10\n",
      "8s - loss: 0.0109 - val_loss: 0.0146\n",
      "Epoch 4/10\n",
      "8s - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 5/10\n",
      "8s - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 6/10\n",
      "8s - loss: 0.0098 - val_loss: 0.0096\n",
      "Epoch 7/10\n",
      "8s - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 8/10\n",
      "8s - loss: 0.0096 - val_loss: 0.0105\n",
      "Epoch 9/10\n",
      "8s - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 10/10\n",
      "8s - loss: 0.0092 - val_loss: 0.0098\n",
      "Actual steering angle 0.0 model prediction -0.022434452548623085\n",
      "Actual steering angle 0.3583844 model prediction 0.1620214730501175\n",
      "Actual steering angle -0.0787459 model prediction -0.02869386598467827\n",
      "Actual steering angle 0.09046549999999999 model prediction 0.011646218597888947\n",
      "Actual steering angle 0.100034 model prediction 0.05777847766876221\n",
      "Actual steering angle 0.0 model prediction 0.00262237386777997\n",
      "Actual steering angle 0.0 model prediction -0.03472411632537842\n",
      "Actual steering angle 0.07132844 model prediction 0.006533768028020859\n",
      "Actual steering angle 0.0 model prediction 0.03093511424958706\n",
      "Actual steering angle 0.0 model prediction 0.01404853630810976\n"
     ]
    }
   ],
   "source": [
    "train(model_4)\n",
    "sample_predictions(model_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer  1 convolution2d_48 input shape (None, 80, 160, 3) output shape (None, 38, 78, 24)\n",
      "Layer  2 activation_88    input shape (None, 38, 78, 24) output shape (None, 38, 78, 24)\n",
      "Layer  3 convolution2d_49 input shape (None, 38, 78, 24) output shape (None, 17, 37, 36)\n",
      "Layer  4 activation_89    input shape (None, 17, 37, 36) output shape (None, 17, 37, 36)\n",
      "Layer  5 convolution2d_50 input shape (None, 17, 37, 36) output shape (None, 7, 17, 48)\n",
      "Layer  6 activation_90    input shape (None, 7, 17, 48) output shape (None, 7, 17, 48)\n",
      "Layer  7 convolution2d_51 input shape (None, 7, 17, 48) output shape (None, 5, 15, 64)\n",
      "Layer  8 activation_91    input shape (None, 5, 15, 64) output shape (None, 5, 15, 64)\n",
      "Layer  9 convolution2d_52 input shape (None, 5, 15, 64) output shape (None, 3, 13, 64)\n",
      "Layer 10 activation_92    input shape (None, 3, 13, 64) output shape (None, 3, 13, 64)\n",
      "Layer 11 flatten_12       input shape (None, 3, 13, 64) output shape (None, 2496)\n",
      "Layer 12 dense_42         input shape (None, 2496) output shape (None, 100)\n",
      "Layer 13 dropout_47       input shape (None, 100) output shape (None, 100)\n",
      "Layer 14 activation_93    input shape (None, 100) output shape (None, 100)\n",
      "Layer 15 dense_43         input shape (None, 100) output shape (None, 50)\n",
      "Layer 16 activation_94    input shape (None, 50) output shape (None, 50)\n",
      "Layer 17 dense_44         input shape (None, 50) output shape (None, 10)\n",
      "Layer 18 activation_95    input shape (None, 10) output shape (None, 10)\n",
      "Layer 19 dense_45         input shape (None, 10) output shape (None, 1)\n"
     ]
    }
   ],
   "source": [
    "model_4 = Sequential()\n",
    "model_4.add(Convolution2D(24, 5, 5, border_mode='valid', subsample=(2, 2), input_shape=(80, 160, 3)))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Convolution2D(36, 5, 5, border_mode='valid', subsample=(2, 2)))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Convolution2D(48, 5, 5, border_mode='valid', subsample=(2, 2)))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Convolution2D(64, 3, 3, border_mode='valid'))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Convolution2D(64, 3, 3, border_mode='valid'))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Flatten())\n",
    "model_4.add(Dense(100))\n",
    "model_4.add(Dropout(0.5))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dense(50))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dense(10))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dense(1))\n",
    "\n",
    "layer_info(model_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6428 samples, validate on 1608 samples\n",
      "Epoch 1/50\n",
      "9s - loss: 0.0127 - val_loss: 0.0112\n",
      "Epoch 2/50\n",
      "7s - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 3/50\n",
      "7s - loss: 0.0094 - val_loss: 0.0105\n",
      "Epoch 4/50\n",
      "7s - loss: 0.0090 - val_loss: 0.0107\n",
      "Epoch 5/50\n",
      "7s - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 6/50\n",
      "7s - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 7/50\n",
      "7s - loss: 0.0076 - val_loss: 0.0108\n",
      "Epoch 8/50\n",
      "7s - loss: 0.0072 - val_loss: 0.0108\n",
      "Epoch 9/50\n",
      "7s - loss: 0.0067 - val_loss: 0.0105\n",
      "Epoch 10/50\n",
      "7s - loss: 0.0061 - val_loss: 0.0113\n",
      "Epoch 11/50\n",
      "7s - loss: 0.0053 - val_loss: 0.0133\n",
      "Epoch 12/50\n",
      "7s - loss: 0.0048 - val_loss: 0.0121\n",
      "Epoch 13/50\n",
      "7s - loss: 0.0041 - val_loss: 0.0112\n",
      "Epoch 14/50\n",
      "7s - loss: 0.0035 - val_loss: 0.0118\n",
      "Epoch 15/50\n",
      "7s - loss: 0.0030 - val_loss: 0.0121\n",
      "Epoch 16/50\n",
      "7s - loss: 0.0029 - val_loss: 0.0142\n",
      "Epoch 17/50\n",
      "7s - loss: 0.0026 - val_loss: 0.0133\n",
      "Epoch 18/50\n",
      "7s - loss: 0.0022 - val_loss: 0.0142\n",
      "Epoch 19/50\n",
      "7s - loss: 0.0020 - val_loss: 0.0141\n",
      "Epoch 20/50\n",
      "7s - loss: 0.0018 - val_loss: 0.0130\n",
      "Epoch 21/50\n",
      "7s - loss: 0.0015 - val_loss: 0.0138\n",
      "Epoch 22/50\n",
      "7s - loss: 0.0017 - val_loss: 0.0128\n",
      "Epoch 23/50\n",
      "7s - loss: 0.0015 - val_loss: 0.0129\n",
      "Epoch 24/50\n",
      "7s - loss: 0.0014 - val_loss: 0.0123\n",
      "Epoch 25/50\n",
      "7s - loss: 0.0014 - val_loss: 0.0123\n",
      "Epoch 26/50\n",
      "7s - loss: 0.0014 - val_loss: 0.0136\n",
      "Epoch 27/50\n",
      "7s - loss: 0.0013 - val_loss: 0.0131\n",
      "Epoch 28/50\n",
      "7s - loss: 0.0014 - val_loss: 0.0117\n",
      "Epoch 29/50\n",
      "7s - loss: 0.0014 - val_loss: 0.0142\n",
      "Epoch 30/50\n",
      "7s - loss: 0.0013 - val_loss: 0.0121\n",
      "Epoch 31/50\n",
      "7s - loss: 0.0013 - val_loss: 0.0120\n",
      "Epoch 32/50\n",
      "7s - loss: 0.0011 - val_loss: 0.0125\n",
      "Epoch 33/50\n",
      "7s - loss: 0.0011 - val_loss: 0.0131\n",
      "Epoch 34/50\n",
      "7s - loss: 9.7220e-04 - val_loss: 0.0128\n",
      "Epoch 35/50\n",
      "7s - loss: 9.4868e-04 - val_loss: 0.0123\n",
      "Epoch 36/50\n",
      "7s - loss: 9.9995e-04 - val_loss: 0.0129\n",
      "Epoch 37/50\n",
      "7s - loss: 0.0011 - val_loss: 0.0124\n",
      "Epoch 38/50\n",
      "7s - loss: 0.0012 - val_loss: 0.0124\n",
      "Epoch 39/50\n",
      "7s - loss: 0.0011 - val_loss: 0.0115\n",
      "Epoch 40/50\n",
      "7s - loss: 0.0011 - val_loss: 0.0121\n",
      "Epoch 41/50\n",
      "7s - loss: 9.6353e-04 - val_loss: 0.0122\n",
      "Epoch 42/50\n",
      "7s - loss: 9.7532e-04 - val_loss: 0.0126\n",
      "Epoch 43/50\n",
      "7s - loss: 0.0010 - val_loss: 0.0123\n",
      "Epoch 44/50\n",
      "7s - loss: 9.7824e-04 - val_loss: 0.0131\n",
      "Epoch 45/50\n",
      "7s - loss: 9.1034e-04 - val_loss: 0.0124\n",
      "Epoch 46/50\n",
      "7s - loss: 9.1195e-04 - val_loss: 0.0127\n",
      "Epoch 47/50\n",
      "7s - loss: 9.7430e-04 - val_loss: 0.0129\n",
      "Epoch 48/50\n",
      "7s - loss: 0.0010 - val_loss: 0.0123\n",
      "Epoch 49/50\n",
      "7s - loss: 9.5785e-04 - val_loss: 0.0122\n",
      "Epoch 50/50\n",
      "7s - loss: 8.3990e-04 - val_loss: 0.0123\n",
      "Actual steering angle 0.0 model prediction 0.026736818253993988\n",
      "Actual steering angle 0.01391724 model prediction 0.0025174468755722046\n",
      "Actual steering angle 0.0 model prediction 0.0025174468755722046\n",
      "Actual steering angle 0.0 model prediction 0.0025174468755722046\n",
      "Actual steering angle 0.0 model prediction 0.0025174468755722046\n",
      "Actual steering angle 0.09046549999999999 model prediction 0.042016007006168365\n",
      "Actual steering angle 0.061759900000000006 model prediction 0.0025174468755722046\n",
      "Actual steering angle 0.0 model prediction 0.0025174468755722046\n",
      "Actual steering angle 0.0 model prediction 0.0025174468755722046\n",
      "Actual steering angle 0.0 model prediction 0.0025174468755722046\n"
     ]
    }
   ],
   "source": [
    "train(model_4, 50, learning_rate=0.001)\n",
    "sample_predictions(model_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual steering angle 0.0 model prediction 0.0025174468755722046\n",
      "Actual steering angle -0.04076847 model prediction -0.026189584285020828\n",
      "Actual steering angle 0.1287396 model prediction 0.1220826581120491\n",
      "Actual steering angle 0.0 model prediction 0.0025174468755722046\n",
      "Actual steering angle -0.08824026 model prediction -0.09228046238422394\n",
      "Actual steering angle 0.0 model prediction 0.0025174468755722046\n",
      "Actual steering angle 0.1957194 model prediction 0.14779014885425568\n",
      "Actual steering angle 0.0 model prediction 0.0025174468755722046\n",
      "Actual steering angle 0.0 model prediction -0.010257076472043991\n",
      "Actual steering angle 0.07132844 model prediction 0.08812379837036133\n"
     ]
    }
   ],
   "source": [
    "sample_predictions(model_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
