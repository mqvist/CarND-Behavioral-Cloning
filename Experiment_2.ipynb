{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, I want to continue working with the model form the experiment 1. The model was able to learn the steering angles for the three hand-picked images but the question is can it learn to actually steer the car in the simulator's autonomous mode. Given the discussion about recovery in the project material, it is unlikely that the provided sample training data is enough to teach the model to drive, but doing a test with that data would give at least a baseline to work from.\n",
    "\n",
    "Here is the overall plan\n",
    "1. Recreate the model from experiment 1\n",
    "1. Create training data using the provided sample data\n",
    "1. Train the model using the whole training data and see if it any learning takes place\n",
    "1. If needed, tweak the model to get better training performance\n",
    "1. Test the model with the simulator to see how it performs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def get_record_and_image(index):\n",
    "    record = df.iloc[index]\n",
    "    path = os.path.join('data', record.center)\n",
    "    return record, Image.open(path)\n",
    "\n",
    "def layer_info(model):\n",
    "    for n, layer in enumerate(model.layers, 1):\n",
    "        print('Layer {:2} {:16} input shape {} output shape {}'.format(n, layer.name, layer.input_shape, layer.output_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Recreate the model from experiment 1\n",
    "\n",
    "This is an exact copy of the model from experiment 1 with one difference: the input image size is halved, because the images will be downscaled this time. The reason for the downscaling is explained in Step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer  1 convolution2d_25 input shape (None, 80, 160, 3) output shape (None, 16, 32, 6)\n",
      "Layer  2 activation_61    input shape (None, 16, 32, 6) output shape (None, 16, 32, 6)\n",
      "Layer  3 maxpooling2d_21  input shape (None, 16, 32, 6) output shape (None, 8, 16, 6)\n",
      "Layer  4 convolution2d_26 input shape (None, 8, 16, 6) output shape (None, 2, 6, 16)\n",
      "Layer  5 activation_62    input shape (None, 2, 6, 16) output shape (None, 2, 6, 16)\n",
      "Layer  6 maxpooling2d_22  input shape (None, 2, 6, 16) output shape (None, 1, 3, 16)\n",
      "Layer  7 flatten_13       input shape (None, 1, 3, 16) output shape (None, 48)\n",
      "Layer  8 dense_37         input shape (None, 48) output shape (None, 120)\n",
      "Layer  9 activation_63    input shape (None, 120) output shape (None, 120)\n",
      "Layer 10 dense_38         input shape (None, 120) output shape (None, 84)\n",
      "Layer 11 activation_64    input shape (None, 84) output shape (None, 84)\n",
      "Layer 12 dense_39         input shape (None, 84) output shape (None, 1)\n",
      "Layer 13 activation_65    input shape (None, 1) output shape (None, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(6, 5, 5, border_mode='valid', subsample=(5, 5), input_shape=(80, 160, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(16, 5, 5, border_mode='valid', subsample=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(84))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('tanh'))\n",
    "\n",
    "layer_info(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/driving_log.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to create the actual training data, X_train and y_train. I will just read all the images and store them as NumPy arrays to X_train. Similary, I read the corresponding steering angles and store them to y_train.\n",
    "\n",
    "Note: I ended up scaling the images down to half size to conserve memory and speed up training. This was also mentioned in the project cheat sheet (https://carnd-forums.udacity.com/questions/26214464/behavioral-cloning-cheatsheet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8036/8036 [00:40<00:00, 200.22it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    record, image = get_record_and_image(i)\n",
    "    image = image.resize((image.width // 2, image.height // 2))\n",
    "    X_train.append(np.array(image))\n",
    "    image.close()\n",
    "    y_train.append(record['steering'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some preprocessing: normalize the images and convert the y_train to a NumPy array because that is what the Keras fit() seems to want. This step takes some time and consumes also a lot of memory; downscaling the images above helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_min = np.min(X_train)\n",
    "X_max = np.max(X_train)\n",
    "X_normalized = (X_train - X_min) / (X_max - X_min) - 0.5\n",
    "y_train = np.array(steering_angles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train the model\n",
    "\n",
    "Here I use all the data from the sample training data, 8036 images and their steering angles. Instead of using the training data generator as in the experiment 1, I just give the whole training set to model.fit and let it split it to training and validation sets. After training, I save the model so it can be loaded to the simulator for testing if the training seems to proceed well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, nb_epoch=10):\n",
    "    model.compile('adam', 'mse')\n",
    "    model.fit(X_normalized, y_train, validation_split=0.2, nb_epoch=nb_epoch, verbose=2)\n",
    "    model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6428 samples, validate on 1608 samples\n",
      "Epoch 1/10\n",
      "12s - loss: 0.0132 - val_loss: 0.0122\n",
      "Epoch 2/10\n",
      "11s - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 3/10\n",
      "11s - loss: 0.0093 - val_loss: 0.0110\n",
      "Epoch 4/10\n",
      "11s - loss: 0.0086 - val_loss: 0.0111\n",
      "Epoch 5/10\n",
      "11s - loss: 0.0080 - val_loss: 0.0109\n",
      "Epoch 6/10\n",
      "12s - loss: 0.0075 - val_loss: 0.0107\n",
      "Epoch 7/10\n",
      "11s - loss: 0.0072 - val_loss: 0.0124\n",
      "Epoch 8/10\n",
      "11s - loss: 0.0068 - val_loss: 0.0106\n",
      "Epoch 9/10\n",
      "11s - loss: 0.0064 - val_loss: 0.0116\n",
      "Epoch 10/10\n",
      "11s - loss: 0.0061 - val_loss: 0.0113\n"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation error does not get much lower after epoch 4 or so, whereas the training error keeps falling. This indicates overtraining and poor generalization ability. \n",
    "\n",
    "Lets do a bit of random sampling of the predicted steering angles to get a feeling how they match with the actual angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual steering angle 0.0 model prediction 0.1719207465648651\n",
      "Actual steering angle 0.0 model prediction 0.028600577265024185\n",
      "Actual steering angle 0.0 model prediction 0.017018768936395645\n",
      "Actual steering angle 0.0 model prediction -0.05043351650238037\n",
      "Actual steering angle -0.41104840000000004 model prediction -0.14591500163078308\n",
      "Actual steering angle 0.0 model prediction -0.03481806069612503\n",
      "Actual steering angle 0.0 model prediction 0.023184774443507195\n",
      "Actual steering angle 0.0 model prediction -0.05616610124707222\n",
      "Actual steering angle 0.1287396 model prediction 0.16128838062286377\n",
      "Actual steering angle -0.0787459 model prediction -0.05938925966620445\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "\n",
    "def sample_predictions(model):\n",
    "    for i in range(10):\n",
    "        index = randrange(len(df))\n",
    "        X = np.expand_dims(X_normalized[index], axis=0)\n",
    "        y = y_train[index]\n",
    "        print('Actual steering angle {} model prediction {}'.format(y, model.predict(X)[0][0]))\n",
    "        \n",
    "sample_predictions(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The sample predictions do not look very good. Some tweaks to the model are in place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Tweaking the model\n",
    "\n",
    "So what could be done to the model to improve it? Basically there are three different approaches for changing the model:\n",
    "\n",
    "1. Keep the model as it is, but try to improve its generalization ability\n",
    "2. Keep the current architecture, but increase the amount of weights\n",
    "3. Do some changes to the model's architecture\n",
    "\n",
    "Before going for options 2 or 3, let's consider option 1 as it is more conservative than the other. A simple way to try to increase the generalization ability is add dropout layers, which force the model to learn redundant connections. Let's try that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer  1 convolution2d_27 input shape (None, 80, 160, 3) output shape (None, 16, 32, 6)\n",
      "Layer  2 dropout_11       input shape (None, 16, 32, 6) output shape (None, 16, 32, 6)\n",
      "Layer  3 activation_66    input shape (None, 16, 32, 6) output shape (None, 16, 32, 6)\n",
      "Layer  4 maxpooling2d_23  input shape (None, 16, 32, 6) output shape (None, 8, 16, 6)\n",
      "Layer  5 convolution2d_28 input shape (None, 8, 16, 6) output shape (None, 2, 6, 16)\n",
      "Layer  6 dropout_12       input shape (None, 2, 6, 16) output shape (None, 2, 6, 16)\n",
      "Layer  7 activation_67    input shape (None, 2, 6, 16) output shape (None, 2, 6, 16)\n",
      "Layer  8 maxpooling2d_24  input shape (None, 2, 6, 16) output shape (None, 1, 3, 16)\n",
      "Layer  9 flatten_14       input shape (None, 1, 3, 16) output shape (None, 48)\n",
      "Layer 10 dense_40         input shape (None, 48) output shape (None, 120)\n",
      "Layer 11 activation_68    input shape (None, 120) output shape (None, 120)\n",
      "Layer 12 dense_41         input shape (None, 120) output shape (None, 84)\n",
      "Layer 13 activation_69    input shape (None, 84) output shape (None, 84)\n",
      "Layer 14 dense_42         input shape (None, 84) output shape (None, 1)\n",
      "Layer 15 activation_70    input shape (None, 1) output shape (None, 1)\n"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Convolution2D(6, 5, 5, border_mode='valid', subsample=(5, 5), input_shape=(80, 160, 3)))\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_2.add(Convolution2D(16, 5, 5, border_mode='valid', subsample=(2, 2)))\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(120))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Dense(84))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Dense(1))\n",
    "model_2.add(Activation('tanh'))\n",
    "\n",
    "layer_info(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6428 samples, validate on 1608 samples\n",
      "Epoch 1/10\n",
      "13s - loss: 0.0176 - val_loss: 0.0156\n",
      "Epoch 2/10\n",
      "12s - loss: 0.0145 - val_loss: 0.0145\n",
      "Epoch 3/10\n",
      "12s - loss: 0.0135 - val_loss: 0.0135\n",
      "Epoch 4/10\n",
      "12s - loss: 0.0128 - val_loss: 0.0139\n",
      "Epoch 5/10\n",
      "12s - loss: 0.0118 - val_loss: 0.0156\n",
      "Epoch 6/10\n",
      "12s - loss: 0.0116 - val_loss: 0.0143\n",
      "Epoch 7/10\n",
      "12s - loss: 0.0111 - val_loss: 0.0134\n",
      "Epoch 8/10\n",
      "12s - loss: 0.0111 - val_loss: 0.0127\n",
      "Epoch 9/10\n",
      "12s - loss: 0.0107 - val_loss: 0.0139\n",
      "Epoch 10/10\n",
      "12s - loss: 0.0107 - val_loss: 0.0131\n",
      "Actual steering angle 0.1478767 model prediction 0.026851575821638107\n",
      "Actual steering angle 0.0 model prediction 0.03950202092528343\n",
      "Actual steering angle 0.1765823 model prediction 0.04238557070493698\n",
      "Actual steering angle 0.0 model prediction 0.013100355863571167\n",
      "Actual steering angle -0.002791043 model prediction -0.016838598996400833\n",
      "Actual steering angle 0.1957194 model prediction 0.07659861445426941\n",
      "Actual steering angle 0.1765823 model prediction 0.06811440736055374\n",
      "Actual steering angle 0.0 model prediction -0.008444467559456825\n",
      "Actual steering angle 0.0 model prediction 0.010856500826776028\n",
      "Actual steering angle 0.0 model prediction -0.0298810675740242\n"
     ]
    }
   ],
   "source": [
    "train(model_2)\n",
    "sample_predictions(model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performace is even poorer now so the model is probably not complex enough to learn the given data set. I could increase the layer dimensions directly, but there is another way: remove the pooling layers. Pooling is analogous to downsampling and it reduces the amount of weights in the model. Let's strip the pooling layers and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer  1 convolution2d_29 input shape (None, 80, 160, 3) output shape (None, 16, 32, 6)\n",
      "Layer  2 dropout_13       input shape (None, 16, 32, 6) output shape (None, 16, 32, 6)\n",
      "Layer  3 activation_71    input shape (None, 16, 32, 6) output shape (None, 16, 32, 6)\n",
      "Layer  4 convolution2d_30 input shape (None, 16, 32, 6) output shape (None, 12, 28, 16)\n",
      "Layer  5 dropout_14       input shape (None, 12, 28, 16) output shape (None, 12, 28, 16)\n",
      "Layer  6 activation_72    input shape (None, 12, 28, 16) output shape (None, 12, 28, 16)\n",
      "Layer  7 flatten_15       input shape (None, 12, 28, 16) output shape (None, 5376)\n",
      "Layer  8 dense_43         input shape (None, 5376) output shape (None, 120)\n",
      "Layer  9 activation_73    input shape (None, 120) output shape (None, 120)\n",
      "Layer 10 dense_44         input shape (None, 120) output shape (None, 84)\n",
      "Layer 11 activation_74    input shape (None, 84) output shape (None, 84)\n",
      "Layer 12 dense_45         input shape (None, 84) output shape (None, 1)\n",
      "Layer 13 activation_75    input shape (None, 1) output shape (None, 1)\n"
     ]
    }
   ],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(Convolution2D(6, 5, 5, border_mode='valid', subsample=(5, 5), input_shape=(80, 160, 3)))\n",
    "model_3.add(Dropout(0.5))\n",
    "model_3.add(Activation('relu'))\n",
    "#model_3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_3.add(Convolution2D(16, 5, 5, border_mode='valid'))\n",
    "model_3.add(Dropout(0.5))\n",
    "model_3.add(Activation('relu'))\n",
    "#model_3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_3.add(Flatten())\n",
    "model_3.add(Dense(120))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(Dense(84))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(Dense(1))\n",
    "model_3.add(Activation('tanh'))\n",
    "\n",
    "layer_info(model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6428 samples, validate on 1608 samples\n",
      "Epoch 1/20\n",
      "26s - loss: 0.0085 - val_loss: 0.0108\n",
      "Epoch 2/20\n",
      "25s - loss: 0.0083 - val_loss: 0.0105\n",
      "Epoch 3/20\n",
      "24s - loss: 0.0082 - val_loss: 0.0106\n",
      "Epoch 4/20\n",
      "24s - loss: 0.0081 - val_loss: 0.0101\n",
      "Epoch 5/20\n",
      "25s - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 6/20\n",
      "27s - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 7/20\n",
      "25s - loss: 0.0074 - val_loss: 0.0104\n",
      "Epoch 8/20\n",
      "26s - loss: 0.0077 - val_loss: 0.0098\n",
      "Epoch 9/20\n",
      "26s - loss: 0.0075 - val_loss: 0.0099\n",
      "Epoch 10/20\n",
      "24s - loss: 0.0073 - val_loss: 0.0103\n",
      "Epoch 11/20\n",
      "25s - loss: 0.0076 - val_loss: 0.0098\n",
      "Epoch 12/20\n",
      "25s - loss: 0.0073 - val_loss: 0.0098\n",
      "Epoch 13/20\n",
      "24s - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 14/20\n",
      "25s - loss: 0.0072 - val_loss: 0.0101\n",
      "Epoch 15/20\n",
      "25s - loss: 0.0071 - val_loss: 0.0100\n",
      "Epoch 16/20\n",
      "25s - loss: 0.0071 - val_loss: 0.0100\n",
      "Epoch 17/20\n",
      "25s - loss: 0.0069 - val_loss: 0.0101\n",
      "Epoch 18/20\n",
      "25s - loss: 0.0068 - val_loss: 0.0103\n",
      "Epoch 19/20\n",
      "25s - loss: 0.0065 - val_loss: 0.0100\n",
      "Epoch 20/20\n",
      "25s - loss: 0.0068 - val_loss: 0.0102\n",
      "Actual steering angle -0.04076847 model prediction -0.03412507846951485\n",
      "Actual steering angle -0.0787459 model prediction -0.021964488551020622\n",
      "Actual steering angle 0.0 model prediction 0.016154486685991287\n",
      "Actual steering angle 0.0 model prediction 0.016839727759361267\n",
      "Actual steering angle 0.0 model prediction 0.006399562116712332\n",
      "Actual steering angle -0.11672329999999999 model prediction -0.00500487582758069\n",
      "Actual steering angle 0.0 model prediction 0.09164431691169739\n",
      "Actual steering angle 0.0 model prediction 0.017087172716856003\n",
      "Actual steering angle 0.0 model prediction 0.060469530522823334\n",
      "Actual steering angle -0.0787459 model prediction -0.04608553647994995\n"
     ]
    }
   ],
   "source": [
    "train(model_3, 20)\n",
    "sample_predictions(model_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit better but even after 20 epochs not that much of an improvement. I begin to suspect that I need to increase the model's complexity quite a bit. At this point I will try to replicate the architecture from the NVidia paper (http://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf) and see what kind of difference it makes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer  1 convolution2d_51 input shape (None, 80, 160, 3) output shape (None, 38, 78, 24)\n",
      "Layer  2 activation_117   input shape (None, 38, 78, 24) output shape (None, 38, 78, 24)\n",
      "Layer  3 convolution2d_52 input shape (None, 38, 78, 24) output shape (None, 17, 37, 36)\n",
      "Layer  4 activation_118   input shape (None, 17, 37, 36) output shape (None, 17, 37, 36)\n",
      "Layer  5 convolution2d_53 input shape (None, 17, 37, 36) output shape (None, 7, 17, 48)\n",
      "Layer  6 activation_119   input shape (None, 7, 17, 48) output shape (None, 7, 17, 48)\n",
      "Layer  7 convolution2d_54 input shape (None, 7, 17, 48) output shape (None, 5, 15, 64)\n",
      "Layer  8 activation_120   input shape (None, 5, 15, 64) output shape (None, 5, 15, 64)\n",
      "Layer  9 convolution2d_55 input shape (None, 5, 15, 64) output shape (None, 3, 13, 64)\n",
      "Layer 10 activation_121   input shape (None, 3, 13, 64) output shape (None, 3, 13, 64)\n",
      "Layer 11 flatten_23       input shape (None, 3, 13, 64) output shape (None, 2496)\n",
      "Layer 12 dense_67         input shape (None, 2496) output shape (None, 100)\n",
      "Layer 13 activation_122   input shape (None, 100) output shape (None, 100)\n",
      "Layer 14 dense_68         input shape (None, 100) output shape (None, 50)\n",
      "Layer 15 activation_123   input shape (None, 50) output shape (None, 50)\n",
      "Layer 16 dense_69         input shape (None, 50) output shape (None, 10)\n",
      "Layer 17 activation_124   input shape (None, 10) output shape (None, 10)\n",
      "Layer 18 dense_70         input shape (None, 10) output shape (None, 1)\n",
      "Layer 19 activation_125   input shape (None, 1) output shape (None, 1)\n"
     ]
    }
   ],
   "source": [
    "model_4 = Sequential()\n",
    "model_4.add(Convolution2D(24, 5, 5, border_mode='valid', subsample=(2, 2), input_shape=(80, 160, 3)))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Convolution2D(36, 5, 5, border_mode='valid', subsample=(2, 2)))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Convolution2D(48, 5, 5, border_mode='valid', subsample=(2, 2)))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Convolution2D(64, 3, 3, border_mode='valid'))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Convolution2D(64, 3, 3, border_mode='valid'))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Flatten())\n",
    "model_4.add(Dense(100))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dense(50))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dense(10))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dense(1))\n",
    "model_4.add(Activation('tanh'))\n",
    "\n",
    "layer_info(model_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6428 samples, validate on 1608 samples\n",
      "Epoch 1/10\n",
      "137s - loss: 0.0118 - val_loss: 0.0110\n",
      "Epoch 2/10\n",
      "133s - loss: 0.0095 - val_loss: 0.0104\n",
      "Epoch 3/10\n",
      "130s - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 4/10\n",
      "131s - loss: 0.0084 - val_loss: 0.0111\n",
      "Epoch 5/10\n",
      "130s - loss: 0.0081 - val_loss: 0.0111\n",
      "Epoch 6/10\n",
      "133s - loss: 0.0077 - val_loss: 0.0117\n",
      "Epoch 7/10\n",
      "131s - loss: 0.0071 - val_loss: 0.0106\n",
      "Epoch 8/10\n",
      "131s - loss: 0.0065 - val_loss: 0.0111\n",
      "Epoch 9/10\n",
      "131s - loss: 0.0061 - val_loss: 0.0107\n",
      "Epoch 10/10\n",
      "130s - loss: 0.0052 - val_loss: 0.0127\n",
      "Actual steering angle 0.0 model prediction -0.012478272430598736\n",
      "Actual steering angle 0.1765823 model prediction 0.15921710431575775\n",
      "Actual steering angle 0.0 model prediction -0.024579377844929695\n",
      "Actual steering angle 0.0 model prediction -0.008382455445826054\n",
      "Actual steering angle 0.0 model prediction 0.041543230414390564\n",
      "Actual steering angle 0.1670138 model prediction 0.09181094169616699\n",
      "Actual steering angle 0.0 model prediction 0.08386078476905823\n",
      "Actual steering angle 0.0 model prediction 0.08340258151292801\n",
      "Actual steering angle 0.0 model prediction 0.03946525976061821\n",
      "Actual steering angle 0.1765823 model prediction 0.18259404599666595\n"
     ]
    }
   ],
   "source": [
    "train(model_4)\n",
    "sample_predictions(model_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer  1 convolution2d_61 input shape (None, 80, 160, 3) output shape (None, 38, 78, 24)\n",
      "Layer  2 activation_135   input shape (None, 38, 78, 24) output shape (None, 38, 78, 24)\n",
      "Layer  3 dropout_24       input shape (None, 38, 78, 24) output shape (None, 38, 78, 24)\n",
      "Layer  4 convolution2d_62 input shape (None, 38, 78, 24) output shape (None, 17, 37, 36)\n",
      "Layer  5 activation_136   input shape (None, 17, 37, 36) output shape (None, 17, 37, 36)\n",
      "Layer  6 dropout_25       input shape (None, 17, 37, 36) output shape (None, 17, 37, 36)\n",
      "Layer  7 convolution2d_63 input shape (None, 17, 37, 36) output shape (None, 7, 17, 48)\n",
      "Layer  8 activation_137   input shape (None, 7, 17, 48) output shape (None, 7, 17, 48)\n",
      "Layer  9 dropout_26       input shape (None, 7, 17, 48) output shape (None, 7, 17, 48)\n",
      "Layer 10 convolution2d_64 input shape (None, 7, 17, 48) output shape (None, 5, 15, 64)\n",
      "Layer 11 activation_138   input shape (None, 5, 15, 64) output shape (None, 5, 15, 64)\n",
      "Layer 12 dropout_27       input shape (None, 5, 15, 64) output shape (None, 5, 15, 64)\n",
      "Layer 13 convolution2d_65 input shape (None, 5, 15, 64) output shape (None, 3, 13, 64)\n",
      "Layer 14 activation_139   input shape (None, 3, 13, 64) output shape (None, 3, 13, 64)\n",
      "Layer 15 dropout_28       input shape (None, 3, 13, 64) output shape (None, 3, 13, 64)\n",
      "Layer 16 flatten_25       input shape (None, 3, 13, 64) output shape (None, 2496)\n",
      "Layer 17 dense_75         input shape (None, 2496) output shape (None, 100)\n",
      "Layer 18 activation_140   input shape (None, 100) output shape (None, 100)\n",
      "Layer 19 dense_76         input shape (None, 100) output shape (None, 50)\n",
      "Layer 20 activation_141   input shape (None, 50) output shape (None, 50)\n",
      "Layer 21 dense_77         input shape (None, 50) output shape (None, 10)\n",
      "Layer 22 activation_142   input shape (None, 10) output shape (None, 10)\n",
      "Layer 23 dense_78         input shape (None, 10) output shape (None, 1)\n",
      "Layer 24 activation_143   input shape (None, 1) output shape (None, 1)\n"
     ]
    }
   ],
   "source": [
    "model_4 = Sequential()\n",
    "model_4.add(Convolution2D(24, 5, 5, border_mode='valid', subsample=(2, 2), input_shape=(80, 160, 3)))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dropout(0.5))\n",
    "model_4.add(Convolution2D(36, 5, 5, border_mode='valid', subsample=(2, 2)))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dropout(0.5))\n",
    "model_4.add(Convolution2D(48, 5, 5, border_mode='valid', subsample=(2, 2)))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dropout(0.5))\n",
    "model_4.add(Convolution2D(64, 3, 3, border_mode='valid'))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dropout(0.5))\n",
    "model_4.add(Convolution2D(64, 3, 3, border_mode='valid'))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dropout(0.5))\n",
    "model_4.add(Flatten())\n",
    "model_4.add(Dense(100))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dense(50))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dense(10))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dense(1))\n",
    "model_4.add(Activation('tanh'))\n",
    "\n",
    "layer_info(model_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6428 samples, validate on 1608 samples\n",
      "Epoch 1/10\n",
      "173s - loss: 0.0147 - val_loss: 0.0130\n",
      "Epoch 2/10\n",
      "167s - loss: 0.0113 - val_loss: 0.0112\n",
      "Epoch 3/10\n"
     ]
    }
   ],
   "source": [
    "train(model_4)\n",
    "sample_predictions(model_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
