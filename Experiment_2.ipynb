{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, I want to continue working with the model form the experiment 1. The model was able to learn the steering angles for the three hand-picked images but the question is can it learn to actually steer the car in the simulator's autonomous mode. Given the discussion about recovery in the project material, it is unlikely that the provided sample training data is enough to teach the model to drive, but doing a test with that data would give at least a baseline to work from.\n",
    "\n",
    "Here is the overall plan\n",
    "1. Recreate the model from experiment 1\n",
    "1. Create training data using the provided sample data\n",
    "1. Train the model using the whole training data and see if it any learning takes place\n",
    "1. If needed, tweak the model to get better training performance\n",
    "1. Test the model with the simulator to see how it performs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def get_record_and_image(index):\n",
    "    record = df.iloc[index]\n",
    "    path = os.path.join('data', record.center)\n",
    "    return record, Image.open(path)\n",
    "\n",
    "def layer_info(model):\n",
    "    for n, layer in enumerate(model.layers, 1):\n",
    "        print('Layer {:2} {:16} input shape {} output shape {}'.format(n, layer.name, layer.input_shape, layer.output_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Recreate the model from experiment 1\n",
    "\n",
    "This is an exact copy of the model from experiment 1 with one difference: the input image size is halved, because the images will be downscaled this time. The reason for the downscaling is explained in Step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer  1 convolution2d_15 input shape (None, 80, 160, 3) output shape (None, 16, 32, 6)\n",
      "Layer  2 activation_36    input shape (None, 16, 32, 6) output shape (None, 16, 32, 6)\n",
      "Layer  3 maxpooling2d_13  input shape (None, 16, 32, 6) output shape (None, 8, 16, 6)\n",
      "Layer  4 convolution2d_16 input shape (None, 8, 16, 6) output shape (None, 2, 6, 16)\n",
      "Layer  5 activation_37    input shape (None, 2, 6, 16) output shape (None, 2, 6, 16)\n",
      "Layer  6 maxpooling2d_14  input shape (None, 2, 6, 16) output shape (None, 1, 3, 16)\n",
      "Layer  7 flatten_8        input shape (None, 1, 3, 16) output shape (None, 48)\n",
      "Layer  8 dense_22         input shape (None, 48) output shape (None, 120)\n",
      "Layer  9 activation_38    input shape (None, 120) output shape (None, 120)\n",
      "Layer 10 dense_23         input shape (None, 120) output shape (None, 84)\n",
      "Layer 11 activation_39    input shape (None, 84) output shape (None, 84)\n",
      "Layer 12 dense_24         input shape (None, 84) output shape (None, 1)\n",
      "Layer 13 activation_40    input shape (None, 1) output shape (None, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(6, 5, 5, border_mode='valid', subsample=(5, 5), input_shape=(80, 160, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(16, 5, 5, border_mode='valid', subsample=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(84))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('tanh'))\n",
    "\n",
    "layer_info(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/driving_log.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to create the actual training data, X_train and y_train. I will just read all the images and store them as NumPy arrays to X_train. Similary, I read the corresponding steering angles and store them to y_train.\n",
    "\n",
    "Note: I ended up scaling the images down to half size to conserve memory and speed up training. This was also mentioned in the project cheat sheet (https://carnd-forums.udacity.com/questions/26214464/behavioral-cloning-cheatsheet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8036/8036 [00:40<00:00, 200.22it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    record, image = get_record_and_image(i)\n",
    "    image = image.resize((image.width // 2, image.height // 2))\n",
    "    X_train.append(np.array(image))\n",
    "    image.close()\n",
    "    y_train.append(record['steering'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some preprocessing: normalize the images and convert the y_train to a NumPy array because that is what the Keras fit() seems to want. This step takes some time and consumes also a lot of memory; downscaling the images above helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_min = np.min(X_train)\n",
    "X_max = np.max(X_train)\n",
    "X_normalized = (X_train - X_min) / (X_max - X_min) - 0.5\n",
    "y_train = np.array(steering_angles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train the model\n",
    "\n",
    "Here I use all the data from the sample training data, 8036 images and their steering angles. Instead of using the training data generator as in the experiment 1, I just give the whole training set to model.fit and let it split it to training and validation sets. After training, I save the model so it can be loaded to the simulator for testing if the training seems to proceed well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6428 samples, validate on 1608 samples\n",
      "Epoch 1/10\n",
      "15s - loss: 0.0129 - val_loss: 0.0123\n",
      "Epoch 2/10\n",
      "11s - loss: 0.0102 - val_loss: 0.0115\n",
      "Epoch 3/10\n",
      "11s - loss: 0.0092 - val_loss: 0.0116\n",
      "Epoch 4/10\n",
      "11s - loss: 0.0088 - val_loss: 0.0105\n",
      "Epoch 5/10\n",
      "11s - loss: 0.0082 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "11s - loss: 0.0077 - val_loss: 0.0100\n",
      "Epoch 7/10\n",
      "11s - loss: 0.0074 - val_loss: 0.0112\n",
      "Epoch 8/10\n",
      "11s - loss: 0.0071 - val_loss: 0.0109\n",
      "Epoch 9/10\n",
      "11s - loss: 0.0069 - val_loss: 0.0111\n",
      "Epoch 10/10\n",
      "11s - loss: 0.0064 - val_loss: 0.0109\n"
     ]
    }
   ],
   "source": [
    "model.compile('adam', 'mse')\n",
    "history = model.fit(X_normalized, y_train, validation_split=0.2, nb_epoch=10, verbose=2)\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validator error does not get much lower after epoch 4, whereas the training error keeps falling. This insicates that there is some overtraining going on and the generalization performance is likely poor.\n",
    "\n",
    "Lets do a bit of random sampling of the predicted steering angles to get a feeling how they match with the actual angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual steering angle 0.07132844 model prediction 0.07661744207143784\n",
      "Actual steering angle 0.1765823 model prediction 0.11375436931848526\n",
      "Actual steering angle -0.11672329999999999 model prediction 0.004589824937283993\n",
      "Actual steering angle 0.0 model prediction -0.005036316346377134\n",
      "Actual steering angle 0.3583844 model prediction 0.11509314179420471\n",
      "Actual steering angle 0.07132844 model prediction 0.07235338538885117\n",
      "Actual steering angle 0.0 model prediction -0.013521449640393257\n",
      "Actual steering angle -0.05975719 model prediction -0.08059648424386978\n",
      "Actual steering angle -0.08824026 model prediction -0.04176517203450203\n",
      "Actual steering angle -0.002791043 model prediction 0.015210249461233616\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "\n",
    "for i in range(10):\n",
    "    index = randrange(len(df))\n",
    "    X = np.expand_dims(X_normalized[index], axis=0)\n",
    "    y = y_train[index]\n",
    "    print('Actual steering angle {} model prediction {}'.format(y, model.predict(X)[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The sample do not look very good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer  1 convolution2d_11 input shape (None, 80, 160, 3) output shape (None, 16, 32, 6)\n",
      "Layer  2 dropout_1        input shape (None, 16, 32, 6) output shape (None, 16, 32, 6)\n",
      "Layer  3 activation_26    input shape (None, 16, 32, 6) output shape (None, 16, 32, 6)\n",
      "Layer  4 convolution2d_12 input shape (None, 16, 32, 6) output shape (None, 12, 28, 16)\n",
      "Layer  5 dropout_2        input shape (None, 12, 28, 16) output shape (None, 12, 28, 16)\n",
      "Layer  6 activation_27    input shape (None, 12, 28, 16) output shape (None, 12, 28, 16)\n",
      "Layer  7 flatten_6        input shape (None, 12, 28, 16) output shape (None, 5376)\n",
      "Layer  8 dense_16         input shape (None, 5376) output shape (None, 120)\n",
      "Layer  9 activation_28    input shape (None, 120) output shape (None, 120)\n",
      "Layer 10 dense_17         input shape (None, 120) output shape (None, 84)\n",
      "Layer 11 activation_29    input shape (None, 84) output shape (None, 84)\n",
      "Layer 12 dense_18         input shape (None, 84) output shape (None, 1)\n",
      "Layer 13 activation_30    input shape (None, 1) output shape (None, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(6, 5, 5, border_mode='valid', subsample=(5, 5), input_shape=(80, 160, 3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(16, 5, 5, border_mode='valid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(84))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('tanh'))\n",
    "\n",
    "layer_info(model)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
